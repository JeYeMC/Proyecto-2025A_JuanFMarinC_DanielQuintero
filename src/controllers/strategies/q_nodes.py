import time
from typing import Union
import numpy as np
from src.middlewares.slogger import SafeLogger
from src.funcs.base import emd_efecto, ABECEDARY
from src.middlewares.profile import profiler_manager, profile
from src.funcs.format import fmt_biparte_q
from src.controllers.manager import Manager
from src.models.base.sia import SIA

from src.models.core.solution import Solution
from src.constants.models import (
    QNODES_ANALYSIS_TAG,
    QNODES_LABEL,
    QNODES_STRAREGY_TAG,
)
from src.constants.base import (
    TYPE_TAG,
    NET_LABEL,
    INFTY_NEG,
    INFTY_POS,
    LAST_IDX,
    EFECTO,
    ACTUAL,
)


class QNodes(SIA):
    """
    Clase QNodes para el an√°lisis de redes mediante el algoritmo Q.

    Esta clase implementa un gestor principal para el an√°lisis de redes que utiliza
    el algoritmo Q para encontrar la partici√≥n √≥ptima que minimiza la
    p√©rdida de informaci√≥n en el sistema. Hereda de la clase base SIA (Sistema de
    Informaci√≥n Activo) y proporciona funcionalidades para analizar la estructura
    y din√°mica de la red.

    Args:
    ----
        config (Loader):
            Instancia de la clase Loader que contiene la configuraci√≥n del sistema
            y los par√°metros necesarios para el an√°lisis.

    Attributes:
    ----------
        m (int):
            N√∫mero de elementos en el conjunto de purview (vista).

        n (int):
            N√∫mero de elementos en el conjunto de mecanismos.

        tiempos (tuple[np.ndarray, np.ndarray]):
            Tupla de dos arrays que representan los tiempos para los estados
            actual y efecto del sistema.

        etiquetas (list[tuple]):
            Lista de tuplas conteniendo las etiquetas para los nodos,
            con versiones en min√∫sculas y may√∫sculas del abecedario.

        vertices (set[tuple]):
            Conjunto de v√©rtices que representan los nodos de la red,
            donde cada v√©rtice es una tupla (tiempo, √≠ndice).

        memoria (dict):
            Diccionario para almacenar resultados intermedios y finales
            del an√°lisis (memoizaci√≥n).

        logger:
            Instancia del logger configurada para el an√°lisis Q.

    Methods:
    -------
        run(condicion, purview, mechanism):
            Ejecuta el an√°lisis principal de la red con las condiciones,
            purview y mecanismo especificados.

        algorithm(vertices):
            Implementa el algoritmo Q para encontrar la partici√≥n
            √≥ptima del sistema.

        funcion_submodular(deltas, omegas):
            Calcula la funci√≥n submodular para evaluar particiones candidatas.

        view_solution(mip):
            Visualiza la soluci√≥n encontrada en t√©rminos de las particiones
            y sus valores asociados.

        nodes_complement(nodes):
            Obtiene el complemento de un conjunto de nodos respecto a todos
            los v√©rtices del sistema.

    Notes:
    -----
    - La clase implementa una versi√≥n secuencial del algoritmo Q para encontrar la partici√≥n que minimiza la p√©rdida de informaci√≥n.
    - Utiliza memoizaci√≥n para evitar rec√°lculos innecesarios durante el proceso.
    - El an√°lisis se realiza considerando dos tiempos: actual (presente) y
      efecto (futuro).
    """

    def __init__(self, gestor: Manager):
        super().__init__(gestor)
        profiler_manager.start_session(
            f"{NET_LABEL}{len(gestor.estado_inicial)}{gestor.pagina}"
        )
        self.m: int
        self.n: int
        self.tiempos: tuple[np.ndarray, np.ndarray]
        self.etiquetas = [tuple(s.lower() for s in ABECEDARY), ABECEDARY]
        self.vertices: set[tuple]
        # self.memoria_delta = dict()
        self.memoria_omega = dict()
        self.memoria_particiones = dict()

        self.indices_alcance: np.ndarray
        self.indices_mecanismo: np.ndarray

        self.logger = SafeLogger(QNODES_STRAREGY_TAG)

    @profile(context={TYPE_TAG: QNODES_ANALYSIS_TAG})
    def aplicar_estrategia(
        self,
        condicion: str,
        alcance: str,
        mecanismo: str,
    ):
        self.sia_preparar_subsistema(condicion, alcance, mecanismo)

        futuro = tuple(
            (EFECTO, efecto) for efecto in self.sia_subsistema.indices_ncubos
        )
        presente = tuple(
            (ACTUAL, actual) for actual in self.sia_subsistema.dims_ncubos
        )  #

        self.m = self.sia_subsistema.indices_ncubos.size
        self.n = self.sia_subsistema.dims_ncubos.size

        self.indices_alcance = self.sia_subsistema.indices_ncubos
        self.indices_mecanismo = self.sia_subsistema.dims_ncubos

        self.tiempos = (
            np.zeros(self.n, dtype=np.int8),
            np.zeros(self.m, dtype=np.int8),
        )

        vertices = list(presente + futuro)
        self.vertices = set(presente + futuro)
        mip = self.algorithm(vertices)

        fmt_mip = fmt_biparte_q(list(mip), self.nodes_complement(mip))
        perdida_mip, dist_marginal_mip = self.memoria_particiones[mip]

        return Solution(
            estrategia=QNODES_LABEL,
            perdida=perdida_mip,
            distribucion_subsistema=self.sia_dists_marginales,
            distribucion_particion=dist_marginal_mip,
            tiempo_total=time.time() - self.sia_tiempo_inicio,
            particion=fmt_mip,
        )

    def algorithm(self, vertices: list[tuple[int, int]]):
        """
        Implementa el algoritmo Q para encontrar la partici√≥n √≥ptima de un sistema que minimiza la p√©rdida de informaci√≥n, bas√°ndose en principios de submodularidad dentro de la teor√≠a de lainformaci√≥n.

        El algoritmo opera sobre un conjunto de v√©rtices que representan nodos en diferentes tiempos del sistema (presente y futuro). La idea fundamental es construir incrementalmente grupos de nodos que, cuando se particionan, producen la menor p√©rdida posible de informaci√≥n en el sistema.

        Proceso Principal:
        -----------------
        El algoritmo comienza estableciendo dos conjuntos fundamentales: omega (W) y delta.
        Omega siempre inicia con el primer v√©rtice del sistema, mientras que delta contiene todos los v√©rtices restantes. Esta decisi√≥n no es arbitraria - al comenzar con un
        solo elemento en omega, podemos construir grupos de manera incremental evaluando c√≥mo cada adici√≥n afecta la p√©rdida de informaci√≥n.

        La ejecuci√≥n se desarrolla en fases, ciclos e iteraciones, donde cada fase representa un nivel diferente y conlleva a la formaci√≥n de una partici√≥n candidata, cada ciclo representa un incremento de elementos al conjunto W y cada iteraci√≥n determina al final cu√°l es el mejor elemento/cambio/delta para a√±adir en W.
        Fase >> Ciclo >> Iteraci√≥n.

        1. Formaci√≥n Incremental de Grupos:
        El algoritmo mantiene un conjunto omega que crece gradualmente en cada j-iteraci√≥n. En cada paso, eval√∫a todos los deltas restantes para encontrar cu√°l, al unirse con omega produce la menor p√©rdida de informaci√≥n. Este proceso utiliza la funci√≥n submodular para calcular la diferencia entre la EMD (Earth Mover's Distance) de la combinaci√≥n y la EMD individual del delta evaluado.

        2. Evaluaci√≥n de deltas:
        Para cada delta candidato el algoritmo:
        - Calcula su EMD individual si no est√° en memoria.
        - Calcula la EMD de su combinaci√≥n con el conjunto omega actual
        - Determina la diferencia entre estas EMDs (el "costo" de la combinaci√≥n)
        El delta que produce el menor costo se selecciona y se a√±ade a omega.

        3. Formaci√≥n de Nuevos Grupos:
        Al final de cada fase cuando omega crezca lo suficiente, el algoritmo:
        - Toma los √∫ltimos elementos de omega y delta (par candidato).
        - Los combina en un nuevo grupo
        - Actualiza la lista de v√©rtices para la siguiente fase
        Este proceso de agrupamiento permite que el algoritmo construya particiones
        cada vez m√°s complejas y reutilice estos "pares candidatos" para particiones en conjunto.

        Optimizaci√≥n y Memoria:
        ----------------------
        El algoritmo utiliza dos estructuras de memoria clave:
        - individual_memory: Almacena las EMDs y distribuciones de nodos individuales, evitando rec√°lculos muy costosos.
        - partition_memory: Guarda las EMDs y distribuciones de las particiones completas, permitiendo comparar diferentes combinaciones de grupos teniendo en cuenta que su valor real est√° asociado al valor individual de su formaci√≥n delta.

        La memoizaci√≥n es relevante puesto muchos c√°lculos de EMD son computacionalmente costosos y se repiten durante la ejecuci√≥n del algoritmo.

        Resultado:
        ---------------
        Al terminar todas las fases, el algoritmo selecciona la partici√≥n que produjo la menor EMD global, representando la divisi√≥n del sistema que mejor preserva su informaci√≥n causal.

        Args:
            vertices (list[tuple[int, int]]): Lista de v√©rtices donde cada uno es una
                tupla (tiempo, √≠ndice). tiempo=0 para presente (t_0), tiempo=1 para futuro (t_1).

        Returns:
            tuple[float, tuple[tuple[int, int], ...]]: El valor de p√©rdida en la primera posici√≥n, asociado con la partici√≥n √≥ptima encontrada, identificada por la clave en partition_memory que produce la menor EMD.
        """
        omegas_origen = np.array([vertices[0]])
        deltas_origen = np.array(vertices[1:])

        vertices_fase = vertices

        omegas_ciclo = omegas_origen
        deltas_ciclo = deltas_origen

        total = len(vertices_fase) - 2
        for i in range(len(vertices_fase) - 2):
            self.logger.debug(f"total: {total-i}")
            omegas_ciclo = [vertices_fase[0]]
            deltas_ciclo = vertices_fase[1:]

            emd_particion_candidata = INFTY_POS

            for j in range(len(deltas_ciclo) - 1):
                # self.logger.critic(f"   {j=}")
                emd_local = 1e5
                indice_mip: int

                for k in range(len(deltas_ciclo)):
                    emd_union, emd_delta, dist_marginal_delta = self.funcion_submodular(
                        deltas_ciclo[k], omegas_ciclo
                    )
                    emd_iteracion = emd_union - emd_delta

                    if emd_iteracion < emd_local:
                        emd_local = emd_iteracion
                        indice_mip = k

                    emd_particion_candidata = emd_delta
                    dist_particion_candidata = dist_marginal_delta

                    # Punto 2 Taller
                    # ‚úÖ Terminar si p√©rdida es 0
                    # üö® OPTIMIZACI√ìN: si encontramos una partici√≥n con p√©rdida cero, detenemos el an√°lisis
                    if emd_delta == 0.0:
                        # Creamos la clave que representa esta partici√≥n candidata
                        mip_candidata = (
                            tuple(
                                deltas_ciclo[LAST_IDX]
                                if isinstance(deltas_ciclo[LAST_IDX], list)
                                else deltas_ciclo
                            )
                        )

                        # Guardamos esta partici√≥n como soluci√≥n √≥ptima (porque su p√©rdida es 0)
                        self.memoria_particiones[mip_candidata] = emd_delta, dist_marginal_delta

                        # Terminamos el algoritmo inmediatamente (early exit)
                        return mip_candidata
                    ...
                # self.logger.critic(f"       [k]: {indice_mip}")

                omegas_ciclo.append(deltas_ciclo[indice_mip])
                deltas_ciclo.pop(indice_mip)
                ...

            self.memoria_particiones[
                tuple(
                    deltas_ciclo[LAST_IDX]
                    if isinstance(deltas_ciclo[LAST_IDX], list)
                    else deltas_ciclo
                )
            ] = emd_particion_candidata, dist_particion_candidata

            par_candidato = (
                [omegas_ciclo[LAST_IDX]]
                if isinstance(omegas_ciclo[LAST_IDX], tuple)
                else omegas_ciclo[LAST_IDX]
            ) + (
                deltas_ciclo[LAST_IDX]
                if isinstance(deltas_ciclo[LAST_IDX], list)
                else deltas_ciclo
            )

            omegas_ciclo.pop()
            omegas_ciclo.append(par_candidato)

            vertices_fase = omegas_ciclo
            ...

        return min(
            self.memoria_particiones, key=lambda k: self.memoria_particiones[k][0]
        )

    def funcion_submodular(
        self, deltas: Union[tuple, list[tuple]], omegas: list[Union[tuple, list[tuple]]]
    ):
        """
        Eval√∫a el impacto de combinar el conjunto de nodos individual delta y su agrupaci√≥n con el conjunto omega, calculando la diferencia entre EMD (Earth Mover's Distance) de las configuraciones, en conclusi√≥n los nodos delta evaluados individualmente y su combinaci√≥n con el conjunto omega.

        El proceso se realiza en dos fases principales:

        1. Evaluaci√≥n Individual:
           - Crea una copia del estado temporal del subsistema.
           - Activa los nodos delta en su tiempo correspondiente (presente/futuro).
           - Si el delta ya fue evaluado antes, recupera su EMD y distribuci√≥n marginal de memoria
           - Si no, ha de:
             * Identificar dimensiones activas en presente y futuro.
             * Realiza bipartici√≥n del subsistema con esas dimensiones.
             * Calcular la distribuci√≥n marginal y EMD respecto al subsistema.
             * Guarda resultados en memoria para seguro un uso futuro.

        2. Evaluaci√≥n Combinada:
           - Sobre la misma copia temporal, activa tambi√©n los nodos omega.
           - Calcula dimensiones activas totales (delta + omega).
           - Realiza bipartici√≥n del subsistema completo.
           - Obtiene EMD de la combinaci√≥n.

        Args:
            deltas: Un nodo individual (tupla) o grupo de nodos (lista de tuplas)
                   donde cada tupla est√° identificada por su (tiempo, √≠ndice), sea el tiempo t_0 identificado como 0, t_1 como 1 y, el √≠ndice hace referencia a las variables/dimensiones habilitadas para operaciones de substracci√≥n/marginalizaci√≥n sobre el subsistema, tal que genere la partici√≥n.
            omegas: Lista de nodos ya agrupados, puede contener tuplas individuales
                   o listas de tuplas para grupos formados por los pares candidatos o m√°s uniones entre s√≠ (grupos candidatos).

        Returns:
            tuple: (
                EMD de la combinaci√≥n omega y delta,
                EMD del delta individual,
                Distribuci√≥n marginal del delta individual
            )
            Esto lo hice as√≠ para hacer almacenamiento externo de la emd individual y su distribuci√≥n marginal en las particiones candidatas.
        """
        # Punto 2 Taller
        # üö® OPTIMIZACI√ìN: Si la combinaci√≥n omega y delta ya fue evaluada, la devolvemos directamente
        # Inicializamos variables y una estructura temporal para separar presente (0) y futuro (1)
        emd_delta = INFTY_NEG
        temporal = [[], []]

        # Procesamos el nodo o grupo de nodos "delta" y armamos una clave √∫nica para ellos
        if isinstance(deltas, tuple):
            d_tiempo, d_indice = deltas
            temporal[d_tiempo].append(d_indice)
            clave_delta = (d_tiempo, d_indice)  # clave √∫nica si es un solo nodo
        else:
            for delta in deltas:
                d_tiempo, d_indice = delta
                temporal[d_tiempo].append(d_indice)
            clave_delta = tuple(sorted(deltas))  # clave √∫nica si es grupo

        # ‚è≥ MEMOIZACI√ìN: Si ya calculamos esta p√©rdida antes, la usamos
        if clave_delta in self.memoria_omega:
            emd_delta, vector_delta_marginal = self.memoria_omega[clave_delta]
        else:
            # Si no est√° en memoria, realizamos el c√°lculo completo
            copia_delta = self.sia_subsistema

            dims_alcance_delta = temporal[EFECTO]
            dims_mecanismo_delta = temporal[ACTUAL]

            # Bipartimos el sistema con esas dimensiones
            particion_delta = copia_delta.bipartir(
                np.array(dims_alcance_delta, dtype=np.int8),
                np.array(dims_mecanismo_delta, dtype=np.int8),
            )

            # Calculamos distribuci√≥n marginal y p√©rdida EMD
            vector_delta_marginal = particion_delta.distribucion_marginal()
            emd_delta = emd_efecto(vector_delta_marginal, self.sia_dists_marginales)

            # Guardamos el resultado para reusarlo despu√©s
            self.memoria_omega[clave_delta] = (emd_delta, vector_delta_marginal)

        # Uni√≥n #

        for omega in omegas:
            if isinstance(omega, list):
                for omg in omega:
                    o_tiempo, o_indice = omg
                    temporal[o_tiempo].append(o_indice)
            else:
                o_tiempo, o_indice = omega
                temporal[o_tiempo].append(o_indice)

        copia_union = self.sia_subsistema

        dims_alcance_union = temporal[EFECTO]
        dims_mecanismo_union = temporal[ACTUAL]

        particion_union = copia_union.bipartir(
            np.array(dims_alcance_union, dtype=np.int8),
            np.array(dims_mecanismo_union, dtype=np.int8),
        )
        vector_union_marginal = particion_union.distribucion_marginal()
        emd_union = emd_efecto(vector_union_marginal, self.sia_dists_marginales)

        return emd_union, emd_delta, vector_delta_marginal

    def nodes_complement(self, nodes: list[tuple[int, int]]):
        return list(set(self.vertices) - set(nodes))
